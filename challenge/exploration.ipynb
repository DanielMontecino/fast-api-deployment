{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SIGLAORI\"].unique()\n",
    "# We are working on flights that landing off from Santiago, not taking of ass the problem description."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Analysis: First Sight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is the date distribuited?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flights_by_feature(x: pd.DataFrame, y: pd.DataFrame, feat_name: str, ylabel: str, size=(10, 2)) -> None:\n",
    "    plt.figure(figsize = size)\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    sns.barplot(x=x, y=y, color = 'lightblue', alpha=0.9)\n",
    "    plt.title(f'{ylabel} by {feat_name}')\n",
    "    plt.ylabel(f'{ylabel}', fontsize=12)\n",
    "    plt.xlabel(f'{feat_name}', fontsize=12)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_name_map = {\n",
    "    \"OPERA\": \"Airline\",\n",
    "    \"DIA\": \"Day\",\n",
    "    \"MES\": \"Month\",\n",
    "    \"DIANOM\": \"Day in Week\",\n",
    "    \"TIPOVUELO\": \"Type\",\n",
    "    \"SIGLADES\": \"Destination\"\n",
    "}\n",
    "\n",
    "for feat, name in feat_name_map.items():\n",
    "    flights_by_feat = data[feat].value_counts()\n",
    "    idx_by_feat  = flights_by_feat.index\n",
    "    values_by_feat = flights_by_feat.values\n",
    "    if feat == \"DIANOM\":\n",
    "        order = [2, 5, 4, 1, 0, 6, 3]\n",
    "        idx_by_feat = [idx_by_feat[idx] for idx in order]\n",
    "        values_by_feat = [values_by_feat[idx] for idx in order]\n",
    "\n",
    "    plot_flights_by_feature(x=idx_by_feat, y=values_by_feat, feat_name=name, ylabel=\"Flights\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Features Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a. Period of Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_period_day(date):\n",
    "    \n",
    "    date_time = datetime.strptime(date, '%Y-%m-%d %H:%M:%S').time()\n",
    "    morning_min = datetime.strptime(\"05:00\", '%H:%M').time()\n",
    "    morning_max = datetime.strptime(\"11:59\", '%H:%M').time()\n",
    "    afternoon_min = datetime.strptime(\"12:00\", '%H:%M').time()\n",
    "    afternoon_max = datetime.strptime(\"18:59\", '%H:%M').time()\n",
    "    evening_min = datetime.strptime(\"19:00\", '%H:%M').time()\n",
    "    evening_max = datetime.strptime(\"23:59\", '%H:%M').time()\n",
    "    night_min = datetime.strptime(\"00:00\", '%H:%M').time()\n",
    "    night_max = datetime.strptime(\"4:59\", '%H:%M').time()\n",
    "    \n",
    "    if(date_time >= morning_min and date_time <= morning_max):\n",
    "        return 'mañana'\n",
    "    if(date_time >= afternoon_min and date_time <= afternoon_max):\n",
    "        return 'tarde'\n",
    "    if(\n",
    "        (date_time >= evening_min and date_time <= evening_max) or\n",
    "        (date_time >= night_min and date_time <= night_max)\n",
    "    ):\n",
    "        return 'noche'\n",
    "    raise ValueError(f\"Invalid date: {date_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['period_day'] = data['Fecha-I'].apply(get_period_day)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b. High Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def is_high_season(fecha):\n",
    "    fecha_año = int(fecha.split('-')[0])\n",
    "    fecha = datetime.strptime(fecha, '%Y-%m-%d %H:%M:%S')\n",
    "    range1_min = datetime.strptime('15-Dec', '%d-%b').replace(year = fecha_año)\n",
    "    range1_max = datetime.strptime('31-Dec', '%d-%b').replace(year = fecha_año)\n",
    "    range2_min = datetime.strptime('1-Jan', '%d-%b').replace(year = fecha_año)\n",
    "    range2_max = datetime.strptime('3-Mar', '%d-%b').replace(year = fecha_año)\n",
    "    range3_min = datetime.strptime('15-Jul', '%d-%b').replace(year = fecha_año)\n",
    "    range3_max = datetime.strptime('31-Jul', '%d-%b').replace(year = fecha_año)\n",
    "    range4_min = datetime.strptime('11-Sep', '%d-%b').replace(year = fecha_año)\n",
    "    range4_max = datetime.strptime('30-Sep', '%d-%b').replace(year = fecha_año)\n",
    "    \n",
    "    if ((fecha >= range1_min and fecha <= range1_max) or \n",
    "        (fecha >= range2_min and fecha <= range2_max) or \n",
    "        (fecha >= range3_min and fecha <= range3_max) or\n",
    "        (fecha >= range4_min and fecha <= range4_max)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['high_season'] = data['Fecha-I'].apply(is_high_season)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c. Difference in Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_diff(data):\n",
    "    fecha_o = datetime.strptime(data['Fecha-O'], '%Y-%m-%d %H:%M:%S')\n",
    "    fecha_i = datetime.strptime(data['Fecha-I'], '%Y-%m-%d %H:%M:%S')\n",
    "    min_diff = ((fecha_o - fecha_i).total_seconds())/60\n",
    "    return min_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['min_diff'] = data.apply(get_min_diff, axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.d. Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_in_minutes = 15\n",
    "data['delay'] = np.where(data['min_diff'] > threshold_in_minutes, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Analysis: Second Sight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is the delay rate across columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rate_from_column(data, column):\n",
    "    delays = {}\n",
    "    for _, row in data.iterrows():\n",
    "        if row['delay'] == 1:\n",
    "            if row[column] not in delays:\n",
    "                delays[row[column]] = 1\n",
    "            else:\n",
    "                delays[row[column]] += 1\n",
    "    total = data[column].value_counts().to_dict()\n",
    "    \n",
    "    rates = {}\n",
    "    for name, total in total.items():\n",
    "        if name in delays:\n",
    "            rates[name] = round(total / delays[name], 2)\n",
    "        else:\n",
    "            rates[name] = 0\n",
    "            \n",
    "    return pd.DataFrame.from_dict(data = rates, orient = 'index', columns = ['Tasa (%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_name_map = {\n",
    "    \"SIGLADES\": \"Destination\",\n",
    "    \"OPERA\": \"Airline\",\n",
    "    \"MES\": \"Month\",\n",
    "    \"DIANOM\": \"Day in Week\",\n",
    "    \"high_season\": \"High Season\",\n",
    "    \"TIPOVUELO\": \"Type\",\n",
    "    \"period_day\": \"Period of Day\",\n",
    "    \"DIA\": \"Day\",    \n",
    "}\n",
    "\n",
    "for feat, name in feat_name_map.items():\n",
    "    feat_rate = get_rate_from_column(data, feat)['Tasa (%)']\n",
    "    feat_rate_values = data[feat].value_counts().index\n",
    "    if feat == \"DIANOM\":\n",
    "        order = [2, 5, 4, 1, 0, 6, 3]\n",
    "        feat_rate = [feat_rate[idx] for idx in order]\n",
    "        feat_rate_values = [feat_rate_values[idx] for idx in order]\n",
    "    if feat == \"high_season\":\n",
    "        feat_rate_values = [\"Yes\" if i == 1 else \"No\" for i in feat_rate_values]\n",
    "\n",
    "    plot_flights_by_feature(x=feat_rate_values, y=feat_rate, feat_name=name, ylabel=\"Delay Rate [%]\", size=(20, 5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a. Data Split (Training and Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = shuffle(data[['OPERA', 'MES', 'TIPOVUELO', 'SIGLADES', 'DIANOM', 'delay']], random_state = 111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[\"delay\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([\n",
    "    data[\"high_season\"],\n",
    "    pd.get_dummies(data[\"period_day\"], prefix = 'period_day'),\n",
    "    pd.get_dummies(data['OPERA'], prefix = 'OPERA'),\n",
    "    pd.get_dummies(data['TIPOVUELO'], prefix = 'TIPOVUELO'), \n",
    "    pd.get_dummies(data['SIGLADES'], prefix = 'SIGLADES'), \n",
    "    pd.get_dummies(data['MES'], prefix = 'MES'),\n",
    "    pd.get_dummies(data['DIANOM'], prefix = 'DIANOM')\n",
    "    ], \n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "target = data['delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train shape: {x_train.shape} | test shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts('%')*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts('%')*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.b. Model Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.b.i. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "def train_and_eval_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_preds = model.predict(x_test)\n",
    "    y_preds = [1 if y_pred > 0.5 else 0 for y_pred in y_preds]\n",
    "    print(confusion_matrix(y_test, y_preds))\n",
    "    print(classification_report(y_test, y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(random_state=1, learning_rate=0.01)\n",
    "train_and_eval_model(xgb_model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.b.ii. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "reg_model = LogisticRegression()\n",
    "train_and_eval_model(reg_model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Analysis: Third Sight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plot_importance(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_important_features(model, n_features):\n",
    "    fimportance = model.get_booster().get_score(importance_type=\"gain\") \n",
    "    fimportance = dict(sorted(fimportance.items(), key=lambda item: item[1])[-n_features::])\n",
    "\n",
    "    top_10_features = list(fimportance.keys())\n",
    "    return top_10_features\n",
    "\n",
    "top_10_features = get_most_important_features(xgb_model, 10)\n",
    "top_10_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_y0 = len(y_train[y_train == 0])\n",
    "n_y1 = len(y_train[y_train == 1])\n",
    "scale = n_y0/n_y1\n",
    "print(scale)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training with Improvement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.a. Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(features[top_10_features], target, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.b. Model Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.b.i. XGBoost with Feature Importance and with Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_2 = xgb.XGBClassifier(random_state=1, learning_rate=0.01, scale_pos_weight = scale)\n",
    "train_and_eval_model(xgb_model_2, x_train2, y_train2, x_test2, y_test2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.b.ii. XGBoost with Feature Importance but without Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_3 = xgb.XGBClassifier(random_state=1, learning_rate=0.01)\n",
    "train_and_eval_model(xgb_model_3, x_train2, y_train2, x_test2, y_test2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.b.iii. Logistic Regression with Feature Importante and with Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_2 = LogisticRegression(class_weight={1: n_y0/len(y_train), 0: n_y1/len(y_train)})\n",
    "train_and_eval_model(reg_model_2, x_train2, y_train2, x_test2, y_test2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.b.iv. Logistic Regression with Feature Importante but without Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_3 = LogisticRegression()\n",
    "train_and_eval_model(reg_model_3, x_train2, y_train2, x_test2, y_test2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Science Conclusions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the results of the 6 trained models, it can be determined:\n",
    "- There is no noticeable difference in results between XGBoost and LogisticRegression.\n",
    "- Does not decrease the performance of the model by reducing the features to the 10 most important.\n",
    "- Improves the model's performance when balancing classes, since it increases the recall of class \"1\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With this, the model to be productive must be the one that is trained with the top 10 features and class balancing, but which one?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
